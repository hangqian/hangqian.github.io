<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="Book details: Bayesian Econometric Modelling for Big Data by Hang Qian.">
    <title>Book Details | Hang Qian</title>
    <link rel="stylesheet" href="style.css">
    <style>
        /* 专为书籍详情页定制的样式 */
        .book-header {
            display: flex;
            gap: 30px;
            align-items: center;
            margin-bottom: 40px;
            background: #f9fbfd;
            padding: 30px;
            border-radius: 8px;
            border-left: 4px solid #FF8A65;
        }
        .book-cover-placeholder {
            flex: 0 0 150px;
            height: 220px;
            background-color: #e0e0e0;
            display: flex;
            align-items: center;
            justify-content: center;
            color: #888;
            font-size: 0.9rem;
            text-align: center;
            border-radius: 4px;
            box-shadow: 0 4px 8px rgba(0,0,0,0.1);
        }
        .book-info h2 {
            margin-bottom: 10px;
            color: #2c3e50;
        }
        .book-info p {
            margin-bottom: 5px;
            color: #555;
        }
        
        .chapter-block {
            margin-bottom: 40px;
            padding-bottom: 20px;
            border-bottom: 1px solid #eaeaea;
        }
        .chapter-block:last-child {
            border-bottom: none;
        }
        .chapter-title {
            font-size: 1.3rem;
            color: #2c6c94;
            margin-bottom: 12px;
        }
        .chapter-abstract {
            font-size: 0.95rem;
            color: #4a5568;
            background-color: #f8f9fa;
            padding: 15px;
            border-left: 3px solid #7CB342;
            margin-bottom: 20px;
            line-height: 1.6;
        }
        
        /* 独立的图片容器，去除背景色干扰 */
        .chapter-image-container {
            margin-bottom: 25px;
            text-align: center;
			background: #f9fbfd;
        }
        
        /* 静态插图的排版样式 */
        .chapter-img {
            max-width: 100%;
            height: auto;
            display: inline-block;
            border-radius: 6px;
            box-shadow: 0 4px 12px rgba(0,0,0,0.08);
        }

        .section-list {
            list-style: none;
            padding-left: 0;
            margin-bottom: 15px;
            columns: 2;
            column-gap: 40px;
        }
        .section-list li {
            font-size: 0.9rem;
            color: #555;
            margin-bottom: 8px;
            break-inside: avoid;
        }
        .code-download-area {
            margin-top: 15px;
            display: inline-block;
        }
        .code-link {
            display: inline-flex;
            align-items: center;
            font-size: 0.95rem;
            color: #e67e22;
            text-decoration: none;
            font-weight: bold;
            background: #fff3e0;
            padding: 5px 12px;
            border-radius: 4px;
            transition: background 0.2s ease;
        }
        .code-link:hover {
            background: #ffe0b2;
            text-decoration: none;
        }
        
        @media (max-width: 768px) {
            .book-header {
                flex-direction: column;
                text-align: center;
            }
            .section-list {
                columns: 1;
            }
        }
    </style>
</head>
<body>

    <header class="sky-header">
        <div class="container header-content">
            <div class="title-area">
                <h1>Hang Qian</h1>
                <p class="motto">Principal Engineer, MATLAB Econometrics Toolbox</p>
            </div>
            <nav class="pill-nav">
                <a href="index.html" class="nav-btn">Home</a>
                <a href="book.html" class="nav-btn active">Book</a>
                <a href="research.html" class="nav-btn">Paper</a>
                <a href="video.html" target="_blank" class="nav-btn">Course Video</a>
            </nav>
        </div>
    </header>

    <main class="container">
        
        <section class="book-header">
            <div class="book-cover-placeholder">
                <img src="bookCover.jpg" alt="Book Cover" style="width:100%; height:100%; object-fit:cover; border-radius:4px;" onerror="this.style.display='none'; this.parentNode.innerHTML='Book Cover<br>Image'">
            </div>
            <div class="book-info">
                <h2>Bayesian Econometric Modelling for Big Data</h2>
                <p><strong>Author:</strong> Hang Qian</p>
                <p><strong>Publisher:</strong> Chapman and Hall/CRC</p>
                <p><strong>Series:</strong> Series on Statistics in Business and Economics</p>
                <p><strong>Published:</strong> June 19, 2025 | <strong>Pages:</strong> 486</p>
                <p><strong>ISBN:</strong> 9781032915258 | <strong>DOI:</strong> <a href="https://doi.org/10.1201/9781003564027" target="_blank">10.1201/9781003564027</a></p>
            </div>
        </section>

        <h2 class="section-title">Table of Contents & Chapter Summaries</h2>

        <div class="chapter-block">
            <h3 class="chapter-title">Chapter 1: Linear Regressions</h3>
            <div class="chapter-abstract">
                <strong>Abstract:</strong> This chapter focuses on Gaussian linear regressions, serving as the foundational building block for Bayesian econometrics. It introduces Bayesian analysis from a novel perspective, emphasizing the arithmetic operations of summation, subtraction, and multiplication applied to conjugate distributions. Utilizing these arithmetic operators conceptualizes pseudo data, simplifies exact Bayesian inference for massive datasets, and adds an intriguing dimension to exploring traditional econometric models. Furthermore, the chapter covers crucial concepts such as marginal likelihood for model comparison, posterior predictive assessment, and exponential family distributions, equipping readers with scalable tools for big data applications like mortgage shopping and rolling-window regressions.
            </div>
            <div class="chapter-image-container">
                <img src="chapter1.jpg" alt="Conjugate Distribution Addition" class="chapter-img">
            </div>
            <ul class="section-list">
                <li>1.1 Conjugate Distributions</li>
                <li>1.2 NIG Summation</li>
                <li>1.3 NIG Subtraction</li>
                <li>1.4 NIG Scalar Multiplication</li>
                <li>1.5 Marginal Likelihood</li>
                <li>1.6 Prediction</li>
                <li>1.7 Posterior Predictive Assessment</li>
                <li>1.8 Multivariate Extension</li>
                <li>1.9 Extension to Exponential Family</li>
                <li>1.10 Software and Computational Considerations</li>
                <li>1.11 An Application on Mortgage Shopping</li>
                <li>1.12 An Application on Large Bayesian Vector Autoregression</li>
                <li>1.13 An Application on Rolling-window Regressions</li>
            </ul>
            <div class="code-download-area">
                <a href="exampleNIG.zip" class="code-link">[ Download MATLAB Code for Empirical Applications ]</a>
            </div>
        </div>

        <div class="chapter-block">
            <h3 class="chapter-title">Chapter 2: Markov Chain Monte Carlo Methods</h3>
            <div class="chapter-abstract">
                <strong>Abstract:</strong> This chapter provides a comprehensive overview of Markov Chain Monte Carlo (MCMC) methods, which have become the cornerstone of modern Bayesian computation. Unified by the powerful and adaptable Metropolis-Hastings (MH) sampling technique, the text covers foundational algorithms including the Gibbs sampler, slice sampling, and Hamiltonian Monte Carlo. The pseudo-marginal MH sampler makes Bayesian inference feasible for a large collection of statistical models that are difficult to estimate by classical methods. Exact approximation by an unbiased estimator facilitates parameter estimation when the likelihood function is intractable. Recognizing the computational bottlenecks of evaluating target densities in massive datasets, the latter half of the chapter adapts these traditional methods to address big data challenges. Advanced scalable techniques, such as divide-and-conquer strategies and various subsampling methods (e.g., delayed acceptance, firefly Monte Carlo, and stochastic gradient Langevin dynamics), are thoroughly explored alongside practical software implementation considerations.
            </div>
            <div class="chapter-image-container">
                <img src="chapter2.jpg" alt="Divide and Conquer MCMC" class="chapter-img">
            </div>
            <ul class="section-list">
                <li>2.1 Discrete-state MH Sampler</li>
                <li>2.2 MH Sampler in the General Form</li>
                <li>2.3 Gibbs Sampler</li>
                <li>2.4 Hamiltonian Monte Carlo</li>
                <li>2.5 Multiple-try MH Sampler</li>
                <li>2.6 Trans-dimensional MCMC Methods</li>
                <li>2.7 Pseudo-marginal MH Sampler</li>
                <li>2.8 Big Data MCMC: Divide and Conquer</li>
                <li>2.9 Big Data MCMC: Subsampling</li>
                <li>2.10 Software and Computational Considerations</li>
                <li>2.11 An Application on Fertility Choice</li>
            </ul>
            <div class="code-download-area">
                <a href="exampleNIG.zip" class="code-link">[ Download MATLAB Code for Empirical Applications ]</a>
            </div>
        </div>

        <div class="chapter-block">
            <h3 class="chapter-title">Chapter 3: Shrinkage and Variable Selection</h3>
            <div class="chapter-abstract">
                <strong>Abstract:</strong> This chapter highlights the critical importance of incorporating prior information when data alone are insufficient for precise parameter estimation, particularly in the presence of multicollinearity or high-dimensional predictors. It explores various regularization and variable selection methods—including Ridge, Lasso, and Stochastic Search Variable Selection (SSVS)—which penalize excessively large coefficients. These techniques effectively reduce estimation variance, mitigate the risks of overfitting, and significantly improve model interpretability by isolating the most impactful variables. Furthermore, the chapter demonstrates how the normal-inverse-gamma (NIG) summation operator facilitates these shrinkage methods in big data contexts, allowing for efficient MCMC simulations without the need to repeatedly scan the entire dataset.
            </div>
            <div class="chapter-image-container">
                <img src="chapter3.jpg" alt="Ridge and Lasso Regularization" class="chapter-img">
            </div>
            <ul class="section-list">
                <li>3.1 Multicollinearity</li>
                <li>3.2 Ridge Regression</li>
                <li>3.3 Lasso Regression</li>
                <li>3.4 Stochastic Search Variable Selection</li>
                <li>3.5 MCMC Model Composition</li>
                <li>3.6 Software and Computational Considerations</li>
                <li>3.7 An Application on Highest Paying Jobs</li>
            </ul>
            <div class="code-download-area">
                <a href="exampleNIG.zip" class="code-link">[ Download MATLAB Code for Empirical Applications ]</a>
            </div>
        </div>

        <div class="chapter-block">
            <h3 class="chapter-title">Chapter 4: Correlation, Heteroscedasticity and Non-Gaussian Regressions</h3>
            <div class="chapter-abstract">
                <strong>Abstract:</strong> While standard linear regressions often assume independent and identically distributed Gaussian errors for mathematical convenience, real-world data frequently violate these assumptions. This chapter addresses flexible econometric specifications designed to accommodate empirical anomalies such as correlation, heteroscedasticity, skewness, and excess kurtosis (fat tails). By moving beyond the diagonal covariance matrix, it explores stochastic volatility, scale mixtures, and finite mixture distributions, as well as Bayesian nonparametric approaches like Dirichlet Process Mixture Models (DPMM) and quantile regressions. Although these advanced non-Gaussian models typically lack closed-form posteriors, the chapter demonstrates how conditionally conjugate structures can be skillfully exploited to design highly efficient MCMC samplers.
            </div>
            <div class="chapter-image-container">
                <img src="chapter4.jpg" alt="Mixture Distribution and Latent Variables" class="chapter-img">
            </div>
            <ul class="section-list">
                <li>4.1 General Error Covariance Matrix</li>
                <li>4.2 Stochastic Volatility</li>
                <li>4.3 Fat Tail and Scale Mixture Distribution</li>
                <li>4.4 Asymmetry and Skewness</li>
                <li>4.5 Finite Mixture Distribution</li>
                <li>4.6 Dirichlet Process Mixture Models</li>
                <li>4.7 Quantile Regression</li>
                <li>4.8 Model Assessment and Comparison</li>
                <li>4.9 Software and Computational Considerations</li>
                <li>4.10 An Application of Ridesharing Effect by Non-Gaussian Regressions</li>
            </ul>
            <div class="code-download-area">
                <a href="exampleNIG.zip" class="code-link">[ Download MATLAB Code for Empirical Applications ]</a>
            </div>
        </div>

        <div class="chapter-block">
            <h3 class="chapter-title">Chapter 5: Limited Dependent Variable Models</h3>
            <div class="chapter-abstract">
                <strong>Abstract:</strong> Standard linear regression assumes that the dependent variable is continuous and spans the entire real number line, but many economic datasets are inherently constrained. This chapter systematically addresses models for limited dependent variables, offering tailored Bayesian solutions for a variety of data types. It covers binary and multinomial outcomes using Probit and Logistic regressions, handles bounded data through truncated, censored, and Tobit models, and corrects for non-random missing data via sample selection models (incidental truncation). Additionally, it provides specialized frameworks for count data (Poisson regression), duration data (survival analysis), and proportional data (Beta regression), utilizing Metropolis-Hastings and gradient-based numerical optimization for posterior estimation.
            </div>
            <div class="chapter-image-container">
                <img src="chapter5.jpg" alt="Data Augmentation for Classification" class="chapter-img">
            </div>
            <ul class="section-list">
                <li>5.1 Probit Model</li>
                <li>5.2 Logistic Regression</li>
                <li>5.3 Truncation, Censoring and Tobit Model</li>
                <li>5.4 Incidental Truncation and Sample Selection</li>
                <li>5.5 Count Data and Poisson Regression</li>
                <li>5.6 Duration Data and Survival Analysis</li>
                <li>5.7 Beta Regression</li>
                <li>5.8 Software and Computational Considerations</li>
                <li>5.9 An Application of Loan Actions and Mortgage Rates</li>
            </ul>
            <div class="code-download-area">
                <a href="exampleNIG.zip" class="code-link">[ Download MATLAB Code for Empirical Applications ]</a>
            </div>
        </div>

        <div class="chapter-block">
            <h3 class="chapter-title">Chapter 6: Linear State Space Models</h3>
            <div class="chapter-abstract">
                <strong>Abstract:</strong> This chapter introduces linear state space models, a remarkably versatile framework that bridges control system engineering and time series econometrics. Unlike traditional models that solely describe observed data, the state space approach explicitly incorporates latent variables—such as unobserved components, missing data, or time-varying parameters—into a dynamic system. A deep dive is provided into the Kalman filter, a sequential online learning algorithm that recursively updates the posterior state distribution with each new observation. Beyond forward filtering, the chapter covers backward smoothing to refine past estimates. It also unifies state estimation with parameter estimation through likelihood-based inference and Bayesian MCMC simulation, alongside practical strategies for exact initialization and numerical stability.
            </div>
            <div class="chapter-image-container">
                <img src="chapter6.jpg" alt="Kalman Filter Navigation Illustration" class="chapter-img">
            </div>
            <ul class="section-list">
                <li>6.1 Model Specification</li>
                <li>6.2 Kalman Filter</li>
                <li>6.3 More on Kalman Filter</li>
                <li>6.4 Kalman Smoother and Simulation Smoothing</li>
                <li>6.5 Parameter Estimation</li>
                <li>6.6 Initialization of State Space Models</li>
                <li>6.7 Software and Computational Considerations</li>
                <li>6.8 An Application on Exchange Rates</li>
            </ul>
            <div class="code-download-area">
                <a href="exampleNIG.zip" class="code-link">[ Download MATLAB Code for Empirical Applications ]</a>
            </div>
        </div>

        <div class="chapter-block">
            <h3 class="chapter-title">Chapter 7: Nonlinear State Space Models</h3>
            <div class="chapter-abstract">
                <strong>Abstract:</strong> When dealing with nonlinear and non-Gaussian state space models, the analytical tractability of the standard Kalman filter is compromised. This chapter explores a spectrum of advanced methodologies designed to approximate filtering and smoothing distributions under varying degrees of nonlinearity. It begins with specialized non-Gaussian models using data augmentation, before detailing the Extended and Unscented Kalman filters for continuous approximations, and Hidden Markov Models for discrete states. The core focus then shifts to the Particle Filter (Sequential Monte Carlo), providing an in-depth treatment of importance sampling, resampling, and Rao-Blackwellization. The chapter also covers a variety of particle smoothing methods that utilize the entire dataset to approximate the posterior distributions of states. Parameters in nonlinear state space models can be estimated either offline or online. The pseudo-marginal and particle marginal methods combine SMC and MCMC in a principled manner. The correlated pseudo-marginal method significantly enhances the numerical stability of the sampler. Additionally, SMC-Square provides sequential parameter learning methods that update parameters as new data become available.
            </div>
            <div class="chapter-image-container">
                <img src="chapter7.jpg" alt="Particle Filter Approximation" class="chapter-img">
            </div>
            <ul class="section-list">
                <li>7.1 Special Non-Gaussian State Space Models</li>
                <li>7.2 Extended Kalman Filter</li>
                <li>7.3 Unscented Kalman Filter</li>
                <li>7.4 Hidden Markov Model</li>
                <li>7.5 Particle Filter</li>
                <li>7.6 Particle Smoothing</li>
                <li>7.7 Parameter Estimation</li>
                <li>7.8 Parameter Learning</li>
                <li>7.9 Software and Computational Considerations</li>
                <li>7.10 An Application on Inequality Constrained Time-varying-parameter Regression</li>
            </ul>
            <div class="code-download-area">
                <a href="exampleNIG.zip" class="code-link">[ Download MATLAB Code for Empirical Applications ]</a>
            </div>
        </div>

        <div class="chapter-block">
            <h3 class="chapter-title">Chapter 8: Applications of State Space Models</h3>
            <div class="chapter-abstract">
                <strong>Abstract:</strong> As the most extensive chapter of the book, this section demonstrates the remarkable unifying power of the state space framework by applying it to a wide array of prominent econometric models. By casting these diverse methodologies into state space representations, the chapter offers unique insights and scalable estimation techniques for both univariate and multivariate time series. Key models explored in depth include:
                <ul style="margin-top: 8px; margin-bottom: 8px; padding-left: 20px; color: #4a5568;">
                    <li><strong>ARMA & Unobserved Components:</strong> Decomposing time series into local level, trend, seasonality, and cycles.</li>
                    <li><strong>Vector Autoregressions (VAR):</strong> Formulating large Bayesian VARs for macroeconomic forecasting and impulse response analysis.</li>
                    <li><strong>Dynamic Factor Models (DFM):</strong> Extracting latent factors in data-rich environments for nowcasting and yield curve predictions.</li>
                    <li><strong>Time-Varying-Parameter (TVP) Regressions:</strong> Capturing parameter instability and structural breaks over decades of data.</li>
                    <li><strong>Panel Data Analysis:</strong> Seamlessly managing missing data and unifying random/fixed effects within a dynamic framework.</li>
                    <li><strong>Stochastic Volatility (SV):</strong> Extending GARCH models to capture volatility clustering in financial markets via nonlinear state variables.</li>
                    <li><strong>Dynamic Stochastic General Equilibrium (DSGE):</strong> Solving and estimating both linear and nonlinear structural macroeconomic models based on microeconomic foundations.</li>
                </ul>
                The chapter concludes with extensive real-world applications, bridging complex economic theories with empirical data estimation.
            </div>
            <div class="chapter-image-container">
                <img src="chapter8.jpg" alt="State Space Model Furnace" class="chapter-img">
            </div>
            <ul class="section-list">
                <li>8.1 ARMA Models</li>
                <li>8.2 Unobserved Component Models</li>
                <li>8.3 Vector Autoregressions</li>
                <li>8.4 Dynamic Factor Models</li>
                <li>8.5 Time-varying-parameter Regressions</li>
                <li>8.6 Panel Data Analysis</li>
                <li>8.7 From GARCH to Stochastic Volatility</li>
                <li>8.8 Linear DSGE Models</li>
                <li>8.9 Nonlinear DSGE Models</li>
                <li>8.10 Software and Computational Considerations</li>
                <li>8.11 Applications</li>
            </ul>
            <div class="code-download-area">
                <a href="exampleNIG.zip" class="code-link">[ Download MATLAB Code for Empirical Applications ]</a>
            </div>
        </div>

    </main>

    <footer>
        <p>&copy; 2011-2026 Hang Qian. All rights reserved.</p>
    </footer>

</body>
</html>